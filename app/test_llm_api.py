import argparse
from typing import Dict, Union

from models_api.generate import llm


def parse_cli_args() -> argparse.Namespace:
    """
    Parse command line arguments.
    """
    parser = argparse.ArgumentParser(description="Test LLM API")
    parser.add_argument("--prompt", type=str, required=True, help="Prompt to send to the LLM API")
    args = parser.parse_args()
    return args

def generate_response(prompt:str) -> Union[str, Dict]:
    """
    Generate a response using the LLM.
    """
    model = llm("You are a helpful assistant.")
    response_schema = {
        "type": "object",
        "properties": {
            "answer": {
                "type": "string",
                "description": "The response generated by the model."
            }
        },
        "required": ["answer"]
    }
    response = model.generate(prompt, response_schema=response_schema)
    return response


if __name__ == "__main__":
    args = parse_cli_args()
    print("Prompt: ", args.prompt)
    response = generate_response(args.prompt)
    print(f"Response: [{type(response).__name__}]", response, sep="\n")
    print("--------------------------------------------------")

# PLATFORM=vertexai GCLOUD_PROJECT_ID=wmt-mtech-assortment-ml-prod conda run -n ai-analyst-env --cwd /home/jupyter/sao-chat python -m app.test_llm_api --prompt "What is the capital of France?"